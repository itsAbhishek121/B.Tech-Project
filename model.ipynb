{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSlXo7i3AkjW",
        "outputId": "b888dc0f-ffb1-487c-ea8d-0b70cf159785"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lBK9OUPPhgOu"
      },
      "outputs": [],
      "source": [
        "def data_cleaning(input_file):\n",
        "\n",
        "    # Read the CSV file into a Pandas DataFrame\n",
        "    df = pd.read_csv(input_file, encoding='utf-8')\n",
        "\n",
        "    # Remove rows with all empty values\n",
        "    df.dropna(how='all', inplace=True)\n",
        "\n",
        "    # Drop duplicate rows\n",
        "    df.drop_duplicates(inplace=True)\n",
        "\n",
        "    # Remove rows with empty values in a specific column\n",
        "    df.dropna(subset=['Tag'], inplace=True)\n",
        "\n",
        "    # Remove leading and trailing spaces from each column\n",
        "    df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Dictionary for storing all unique words in df[\"Result\"]\n",
        "unique_words = {}\n",
        "\n",
        "def data_preprocessing(df):\n",
        "\n",
        "    # Converting everthing into string datatype.\n",
        "    df['Above Text'] = df['Above Text'].astype(str)\n",
        "    df['Below Text'] = df['Below Text'].astype(str)\n",
        "    df['Row Text'] = df['Row Text'].astype(str)\n",
        "    df['Col Text'] = df['Col Text'].astype(str)\n",
        "\n",
        "    # Concatenate the values in the \"Above Text\", \"Below Text\", \"Row Text\", \"Col Text\" columns with a space.\n",
        "    df['Result'] = df[['Above Text', 'Row Text', 'Col Text', 'Below Text']].apply(lambda x: ' '.join(x), axis=1)\n",
        "\n",
        "    # define a lambda function to convert camelcase string to normal string\n",
        "    to_normal_string = lambda s: ''.join([' ' + i.lower() if i.isupper() else i for i in s]).lstrip(' ')\n",
        "\n",
        "    # apply the lambda function to the column\n",
        "    df['Tag'] = df['Tag'].apply(to_normal_string)\n",
        "\n",
        "    # Convert the text to lowercase\n",
        "    df['Result'] = df['Result'].str.lower()\n",
        "    df['Tag'] = df['Tag'].str.lower()\n",
        "\n",
        "    # Remove punctuation\n",
        "    df['Result'] = df['Result'].str.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Tokenize the strings into individual words\n",
        "    df['Result'] = df['Result'].apply(word_tokenize)\n",
        "\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    stop_words.add('nan')\n",
        "    df['Result'] = df['Result'].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "\n",
        "    # Storing all unique words in dictionary (unique_words)\n",
        "    if (len(unique_words) == 0):\n",
        "        k = 0\n",
        "        for i in df['Result']:\n",
        "                for j in i:\n",
        "                    if j not in unique_words:\n",
        "                        unique_words[j] = k\n",
        "                        k += 1\n",
        "\n",
        "    # Join the stemmed words back into a string\n",
        "    df['Result'] = df['Result'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def vectorizer(df):\n",
        "\n",
        "    # TF-IDF vectorization\n",
        "    v = TfidfVectorizer(vocabulary = unique_words)\n",
        "    x = v.fit_transform(df['Result'])\n",
        "    y = df['Tag']\n",
        "    x = x.toarray()\n",
        "\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def naive_bayes(x_train, y_train, x_test, y_test):\n",
        "\n",
        "    # Train a Naive Bayes model on the preprocessed training data\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(x_train, y_train)\n",
        "\n",
        "    # Test\n",
        "    y_pred = gnb.predict(x_test)\n",
        "    \n",
        "    # Evaluate the accuracy of the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Naive Bayes Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "\n",
        "def decision_trees(x_train, y_train, x_test, y_test):\n",
        "\n",
        "    # Train a Naive Bayes model on the preprocessed training data\n",
        "    dt = DecisionTreeClassifier()\n",
        "    dt.fit(x_train, y_train)\n",
        "\n",
        "    # Test\n",
        "    y_pred = dt.predict(x_test)\n",
        "    \n",
        "    # Evaluate the accuracy of the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Decision Trees Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "\n",
        "def svm(x_train, y_train, x_test, y_test):\n",
        "\n",
        "    # Train a Naive Bayes model on the preprocessed training data\n",
        "    svm = SVC(kernel='linear', C=1, random_state=1)\n",
        "    svm.fit(x_train, y_train)\n",
        "\n",
        "    # Test\n",
        "    y_pred = svm.predict(x_test)\n",
        "    \n",
        "    # Evaluate the accuracy of the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"SVM Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "\n",
        "def knn(x_train, y_train, x_test, y_test):\n",
        "\n",
        "    # Train a Naive Bayes model on the preprocessed training data\n",
        "    knn = KNeighborsClassifier(n_neighbors=5)\n",
        "    knn.fit(x_train, y_train)\n",
        "\n",
        "    # Test\n",
        "    y_pred = knn.predict(x_test)\n",
        "    \n",
        "    # Evaluate the accuracy of the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"KNN Accuracy: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data file\n",
        "train_file = \"train.csv\"\n",
        "\n",
        "# Training data cleaning and preprocessing\n",
        "cleaned_tr_df = data_cleaning(train_file)\n",
        "preprocessed_tr_df = data_preprocessing(cleaned_tr_df)\n",
        "\n",
        "# Vectorization of training data\n",
        "x_train, y_train = vectorizer(preprocessed_tr_df)\n",
        "\n",
        "# Testing data file\n",
        "test_file = \"test.csv\"\n",
        "\n",
        "# Testing data cleaning and preprocessing\n",
        "cleaned_ts_df = data_cleaning(test_file)\n",
        "preprocessed_ts_df = data_preprocessing(cleaned_ts_df)\n",
        "\n",
        "# Vectorization of training data\n",
        "x_test, y_test = vectorizer(preprocessed_ts_df)\n",
        "\n",
        "\n",
        "# Training and Testing on Naive Bayes\n",
        "naive_bayes(x_train, y_train, x_test, y_test)\n",
        "\n",
        "# Training and Testing on Decision Trees\n",
        "decision_trees(x_train, y_train, x_test, y_test)\n",
        "\n",
        "# Training and Testing on SVM\n",
        "svm(x_train, y_train, x_test, y_test)\n",
        "\n",
        "# Training and Testing on KNN\n",
        "knn(x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzjdT_FcBE-t",
        "outputId": "1da20253-a8fc-4950-a871-dc22d2d1a33d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.57\n",
            "Decision Trees Accuracy: 0.77\n",
            "SVM Accuracy: 0.81\n",
            "KNN Accuracy: 1.00\n"
          ]
        }
      ]
    }
  ]
}